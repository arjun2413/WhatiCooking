{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import operator\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import numpy as np\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = json.load(open('train.json'))\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train_data = data[:35000]\n",
    "validation_data = data[35000:]\n",
    "test_data = json.load(open('test.json'))\n",
    "test_ids = [dish['id'] for dish in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopNPerCat(data,labels,N):\n",
    "    #Set data structure to hold word counts\n",
    "    word_count_per_cusine = dict()\n",
    "    for l in labels:\n",
    "        word_count_per_cusine[l] = dict()\n",
    "    \n",
    "    #Get Word Counts for each ingredient per cuisuine\n",
    "    for dish in data:\n",
    "        cuisine = dish['cuisine']\n",
    "        word_count = word_count_per_cusine[cuisine]\n",
    "        \n",
    "        for ing in dish['ingredients']:\n",
    "            if ing not in word_count:\n",
    "                word_count[ing] = 1\n",
    "            else:\n",
    "                word_count[ing] += 1\n",
    "    \n",
    "    \n",
    "    #Get the top N ingredients per cuisine\n",
    "    TopN_Per_Cat = dict()\n",
    "    for l in labels:\n",
    "        word_count = word_count_per_cusine[l]\n",
    "        sorted_word_count = sorted(word_count.items(), key=operator.itemgetter(1))\n",
    "        sorted_word_count.reverse()\n",
    "        TopN_Per_Cat[l] = sorted_word_count[:N]\n",
    "    \n",
    "    #Get all Top N ingredients identified\n",
    "    all_ings_with_count = []\n",
    "    for l in labels:\n",
    "        all_ings_with_count += TopN_Per_Cat[l]\n",
    "        \n",
    "    #Remove Count\n",
    "    all_ings = [ing_count[0] for ing_count in all_ings_with_count]\n",
    "    \n",
    "    #Remove Duplicate ingredients\n",
    "    ing_vector = []\n",
    "    for item in all_ings:\n",
    "        if item not in ing_vector:\n",
    "            ing_vector.append(item)\n",
    "    \n",
    "    #Create dict mapping ingredient to index\n",
    "    ingredient_index = dict()\n",
    "    for i in  range(0,len(ing_vector)):\n",
    "        ingredient_index[ing_vector[i]] = i\n",
    "        \n",
    "    return ingredient_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(preds, labels):\n",
    "    corr = 0\n",
    "    for a,b in zip(preds,labels):\n",
    "        if a == b:\n",
    "            corr += 1\n",
    "    return corr/len(preds)\n",
    "\n",
    "def writeTest(preds):\n",
    "    with open('test_preds.csv', 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow((\"id\",\"cuisine\"))\n",
    "        writer.writerows(zip(test_ids,preds))\n",
    "\n",
    "def getLabels(all_labels):\n",
    "    labels = set()\n",
    "    for l in all_labels:\n",
    "        if l not in labels:\n",
    "            labels.add(l)\n",
    "\n",
    "    return labels\n",
    "  \n",
    "def getWordCounts(data,label):\n",
    "    word_count = dict()\n",
    "    #Get Word Counts for each ingredient per cuisuine\n",
    "    for dish in data:\n",
    "        cuisine = dish['cuisine']\n",
    "        if label == 'all' or label == cuisine:\n",
    "            for ing in dish['ingredients']:\n",
    "                if ing not in word_count:\n",
    "                    word_count[ing] = 1\n",
    "                else:\n",
    "                    word_count[ing] += 1\n",
    "    return word_count\n",
    "\n",
    "def getFrequency(word_count):\n",
    "    freqs = dict()\n",
    "    \n",
    "    total_count = 0\n",
    "    for word in word_count:\n",
    "        total_count += word_count[word]\n",
    "    \n",
    "    for word in word_count:\n",
    "        freqs[word] = word_count[word]/total_count\n",
    "    \n",
    "    return freqs\n",
    "\n",
    "def pickTopNWords(N,freq_overall,freq_cat):\n",
    "    relative_freqs = dict()\n",
    "    \n",
    "    for word in freq_cat:\n",
    "        relative_freqs[word] = freq_cat[word] - freq_overall[word]\n",
    "    \n",
    "    sorted_relative_freqs = sorted(relative_freqs.items(), key=operator.itemgetter(1))\n",
    "    sorted_relative_freqs.reverse()\n",
    "    \n",
    "    TopN = sorted_relative_freqs[:N]\n",
    "    \n",
    "    return set([word for (word,freq) in TopN])\n",
    "    \n",
    "def assignIndex(lst):\n",
    "    item_to_index = dict()\n",
    "    for i in range(0,len(lst)):\n",
    "        item_to_index[lst[i]] = i\n",
    "    \n",
    "    return item_to_index\n",
    "    \n",
    "def getIngredients(data):\n",
    "    ingredients = set()\n",
    "    for dish in data:\n",
    "        for ing in dish['ingredients']:\n",
    "            if ing not in ingredients:\n",
    "                ingredients.add(ing)\n",
    "    \n",
    "    ingredients = list(ingredients)\n",
    "    \n",
    "    ingredient_index = dict()\n",
    "    for i in range(0,len(ingredients)):\n",
    "        ingredient_index[ingredients[i]] = i\n",
    "    \n",
    "    return ingredient_index\n",
    "\n",
    "def oneHotEncode(data,item_to_index):\n",
    "    vectors = []\n",
    "    for dish in data:\n",
    "        vector = [0]*len(item_to_index)\n",
    "        ingredients = dish['ingredients']\n",
    "        for ing in ingredients:\n",
    "            if ing in item_to_index:\n",
    "                index = item_to_index[ing]\n",
    "                vector[index] = 1\n",
    "        \n",
    "        vectors.append(vector)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainY = [dish['cuisine'] for dish in train_data]\n",
    "\n",
    "cuisines = getLabels(trainY)\n",
    "#ingredient_to_index = getTopNPerCat(train_data,cuisines,100)\n",
    "\n",
    "#Get Word Counts\n",
    "overall_word_counts = getWordCounts(train_data,'all')\n",
    "cuisine_word_counts = dict()\n",
    "for cuisine in cuisines:\n",
    "    cuisine_word_counts[cuisine] = getWordCounts(train_data,cuisine)\n",
    "\n",
    "#Get Frequencies\n",
    "overall_frequencies = getFrequency(overall_word_counts)\n",
    "cuisine_frequencies = dict()\n",
    "for cuisine in cuisines:\n",
    "    cuisine_frequencies[cuisine] = getFrequency(cuisine_word_counts[cuisine])\n",
    "    \n",
    "#Get Top Words\n",
    "TopWords = set()\n",
    "for cuisine in cuisines:\n",
    "    TopWords = TopWords | pickTopNWords(100,overall_frequencies,cuisine_frequencies[cuisine])\n",
    "\n",
    "#Assign Index\n",
    "ingredient_to_index = assignIndex(list(TopWords))\n",
    "#ingredient_to_index = getIngredients(data)\n",
    "\n",
    "trainX = oneHotEncode(train_data,ingredient_to_index)\n",
    "#trainY = [dish['cuisine'] for dish in train_data]\n",
    "\n",
    "validationX = oneHotEncode(validation_data,ingredient_to_index)\n",
    "validationY = [dish['cuisine'] for dish in validation_data]\n",
    "\n",
    "testX = oneHotEncode(test_data,ingredient_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "        tol=0.001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RidgeClassifier(alpha=1.0)\n",
    "classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7464285714285714"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Evaluation\n",
    "train_preds = classifier.predict(trainX)\n",
    "evaluate(train_preds,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7276916631755341"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation Evaluation\n",
    "valid_preds = classifier.predict(validationX)\n",
    "evaluate(valid_preds,validationY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write Test Predictions\n",
    "test_preds = classifier.predict(testX)\n",
    "writeTest(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cusines = set()\n",
    "for d in trainY:\n",
    "    if d not in cusines:\n",
    "        cusines.add(d)\n",
    "\n",
    "len(cusines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models TO create\n",
    "Baseline, Naive Bayes, KNN, Random Forest, Ridge, SVM, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = cuisines\n",
    "data = train_data\n",
    "N = 50\n",
    "\n",
    "#Set data structure to hold word counts\n",
    "word_count_per_cusine = dict()\n",
    "for l in labels:\n",
    "    word_count_per_cusine[l] = dict()\n",
    "\n",
    "#Get Word Counts for each ingredient per cuisuine\n",
    "for dish in data:\n",
    "    cuisine = dish['cuisine']\n",
    "    word_count = word_count_per_cusine[cuisine]\n",
    "\n",
    "    for ing in dish['ingredients']:\n",
    "        if ing not in word_count:\n",
    "            word_count[ing] = 1\n",
    "        else:\n",
    "            word_count[ing] += 1\n",
    "\n",
    "\n",
    "#Get the top N ingredients per cuisine\n",
    "TopN_Per_Cat = dict()\n",
    "for l in labels:\n",
    "    word_count = word_count_per_cusine[l]\n",
    "    sorted_word_count = sorted(word_count.items(), key=operator.itemgetter(1))\n",
    "    sorted_word_count.reverse()\n",
    "    TopN_Per_Cat[l] = sorted_word_count[:N]\n",
    "\n",
    "#Get all Top N ingredients identified\n",
    "all_ings_with_count = []\n",
    "for l in labels:\n",
    "    all_ings_with_count += TopN_Per_Cat[l]\n",
    "\n",
    "#Remove Count\n",
    "all_ings = [ing_count[0] for ing_count in all_ings_with_count]\n",
    "\n",
    "#Remove Duplicate ingredients\n",
    "ing_vector = []\n",
    "for item in all_ings:\n",
    "    if item not in ing_vector:\n",
    "        ing_vector.append(item)\n",
    "\n",
    "# #Create dict mapping ingredient to index\n",
    "# ingredient_index = dict()\n",
    "# for i in  range(0,len(ing_vector)):\n",
    "#     ingredient_index[ing_vector[i]] = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = set([1,2,4])\n",
    "s2 = set([1,3,4])\n",
    "s | s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
